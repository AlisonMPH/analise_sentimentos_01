{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Estudo de caso: análise de sentimentos**"
      ],
      "metadata": {
        "id": "eus0SXvwxpmx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pré-processamento**"
      ],
      "metadata": {
        "id": "734uThEKTUIs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "3nEAlGOqxI7I"
      },
      "outputs": [],
      "source": [
        "import nltk"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('rslp')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hybFDVRF6GJg",
        "outputId": "d51cb69d-e6ae-4450-d702-e34a9efc2985"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]   Unzipping stemmers/rslp.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Base de dados (dataset) de frases e emoções**"
      ],
      "metadata": {
        "id": "MaPjVpTWFm4O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = [('estao deixando a gente sonhar', 'alegria'),\n",
        "           ('recebi meu salario extra', 'alegria'),\n",
        "           ('passaremos o Natal em familia', 'alegria'),\n",
        "           ('conseguirei tirar ferias junto com voce', 'alegria'),\n",
        "           ('tirei nota dez na prova', 'alegria'),\n",
        "           ('consegui um emprego novo', 'alegria'),\n",
        "           ('o preco da carne diminuiu', 'alegria'),\n",
        "           ('consegui entregar o trabalho dentro do prazo', 'alegria'),\n",
        "           ('nosso filho nasceu com saude', 'alegria'),\n",
        "           ('a virada de ano foi maravilhosa', 'alegria'),\n",
        "           ('perdi o meu celular', 'tristeza'),\n",
        "           ('minha vida e uma tristeza', 'tristeza'),\n",
        "           ('nao aguento mais isto', 'tristeza'),\n",
        "           ('fazem dois anos que ele se foi', 'tristeza'),\n",
        "           ('infelizmente fui despedido', 'tristeza'),\n",
        "           ('o aumento de salario nao saiu', 'tristeza'),\n",
        "           ('perdi a aposta', 'tristeza'),\n",
        "           ('o pneu do carro furou no meio do caminho', 'tristeza'),\n",
        "           ('teremos que mudar de nossa cidade natal', 'tristeza'),\n",
        "           ('o meu marido me abandonou', 'tristeza')]"
      ],
      "metadata": {
        "id": "NZEcJuFZ07tT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFyBXGzJ3KOA",
        "outputId": "38df91d0-722e-476a-de74-6c515c551d42"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('estao deixando a gente sonhar', 'alegria'), ('recebi meu salario extra', 'alegria'), ('passaremos o Natal em familia', 'alegria'), ('conseguirei tirar ferias junto com voce', 'alegria'), ('tirei nota dez na prova', 'alegria'), ('consegui um emprego novo', 'alegria'), ('o preco da carne diminuiu', 'alegria'), ('consegui entregar o trabalho dentro do prazo', 'alegria'), ('nosso filho nasceu com saude', 'alegria'), ('a virada de ano foi maravilhosa', 'alegria'), ('perdi o meu celular', 'tristeza'), ('minha vida e uma tristeza', 'tristeza'), ('nao aguento mais isto', 'tristeza'), ('fazem dois anos que ele se foi', 'tristeza'), ('infelizmente fui despedido', 'tristeza'), ('o aumento de salario nao saiu', 'tristeza'), ('perdi a aposta', 'tristeza'), ('o pneu do carro furou no meio do caminho', 'tristeza'), ('teremos que mudar de nossa cidade natal', 'tristeza'), ('o meu marido me abandonou', 'tristeza')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Processamento de stopwords**"
      ],
      "metadata": {
        "id": "HE5qcAXXF2We"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words - Tr"
      ],
      "metadata": {
        "id": "WWAjcDNY45BV",
        "outputId": "55eb950a-671d-40f7-e066-42130c3b8462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-aefec05258fa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstopwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mTr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'Tr' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords = nltk.corpus.stopwords.words(\"portuguese\")"
      ],
      "metadata": {
        "id": "xZJgaFac6ifK"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmEB9F7w6k8L",
        "outputId": "bb647041-99a7-4e38-9d13-6ee7ff02a20f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a',\n",
              " 'à',\n",
              " 'ao',\n",
              " 'aos',\n",
              " 'aquela',\n",
              " 'aquelas',\n",
              " 'aquele',\n",
              " 'aqueles',\n",
              " 'aquilo',\n",
              " 'as',\n",
              " 'às',\n",
              " 'até',\n",
              " 'com',\n",
              " 'como',\n",
              " 'da',\n",
              " 'das',\n",
              " 'de',\n",
              " 'dela',\n",
              " 'delas',\n",
              " 'dele',\n",
              " 'deles',\n",
              " 'depois',\n",
              " 'do',\n",
              " 'dos',\n",
              " 'e',\n",
              " 'é',\n",
              " 'ela',\n",
              " 'elas',\n",
              " 'ele',\n",
              " 'eles',\n",
              " 'em',\n",
              " 'entre',\n",
              " 'era',\n",
              " 'eram',\n",
              " 'éramos',\n",
              " 'essa',\n",
              " 'essas',\n",
              " 'esse',\n",
              " 'esses',\n",
              " 'esta',\n",
              " 'está',\n",
              " 'estamos',\n",
              " 'estão',\n",
              " 'estar',\n",
              " 'estas',\n",
              " 'estava',\n",
              " 'estavam',\n",
              " 'estávamos',\n",
              " 'este',\n",
              " 'esteja',\n",
              " 'estejam',\n",
              " 'estejamos',\n",
              " 'estes',\n",
              " 'esteve',\n",
              " 'estive',\n",
              " 'estivemos',\n",
              " 'estiver',\n",
              " 'estivera',\n",
              " 'estiveram',\n",
              " 'estivéramos',\n",
              " 'estiverem',\n",
              " 'estivermos',\n",
              " 'estivesse',\n",
              " 'estivessem',\n",
              " 'estivéssemos',\n",
              " 'estou',\n",
              " 'eu',\n",
              " 'foi',\n",
              " 'fomos',\n",
              " 'for',\n",
              " 'fora',\n",
              " 'foram',\n",
              " 'fôramos',\n",
              " 'forem',\n",
              " 'formos',\n",
              " 'fosse',\n",
              " 'fossem',\n",
              " 'fôssemos',\n",
              " 'fui',\n",
              " 'há',\n",
              " 'haja',\n",
              " 'hajam',\n",
              " 'hajamos',\n",
              " 'hão',\n",
              " 'havemos',\n",
              " 'haver',\n",
              " 'hei',\n",
              " 'houve',\n",
              " 'houvemos',\n",
              " 'houver',\n",
              " 'houvera',\n",
              " 'houverá',\n",
              " 'houveram',\n",
              " 'houvéramos',\n",
              " 'houverão',\n",
              " 'houverei',\n",
              " 'houverem',\n",
              " 'houveremos',\n",
              " 'houveria',\n",
              " 'houveriam',\n",
              " 'houveríamos',\n",
              " 'houvermos',\n",
              " 'houvesse',\n",
              " 'houvessem',\n",
              " 'houvéssemos',\n",
              " 'isso',\n",
              " 'isto',\n",
              " 'já',\n",
              " 'lhe',\n",
              " 'lhes',\n",
              " 'mais',\n",
              " 'mas',\n",
              " 'me',\n",
              " 'mesmo',\n",
              " 'meu',\n",
              " 'meus',\n",
              " 'minha',\n",
              " 'minhas',\n",
              " 'muito',\n",
              " 'na',\n",
              " 'não',\n",
              " 'nas',\n",
              " 'nem',\n",
              " 'no',\n",
              " 'nos',\n",
              " 'nós',\n",
              " 'nossa',\n",
              " 'nossas',\n",
              " 'nosso',\n",
              " 'nossos',\n",
              " 'num',\n",
              " 'numa',\n",
              " 'o',\n",
              " 'os',\n",
              " 'ou',\n",
              " 'para',\n",
              " 'pela',\n",
              " 'pelas',\n",
              " 'pelo',\n",
              " 'pelos',\n",
              " 'por',\n",
              " 'qual',\n",
              " 'quando',\n",
              " 'que',\n",
              " 'quem',\n",
              " 'são',\n",
              " 'se',\n",
              " 'seja',\n",
              " 'sejam',\n",
              " 'sejamos',\n",
              " 'sem',\n",
              " 'ser',\n",
              " 'será',\n",
              " 'serão',\n",
              " 'serei',\n",
              " 'seremos',\n",
              " 'seria',\n",
              " 'seriam',\n",
              " 'seríamos',\n",
              " 'seu',\n",
              " 'seus',\n",
              " 'só',\n",
              " 'somos',\n",
              " 'sou',\n",
              " 'sua',\n",
              " 'suas',\n",
              " 'também',\n",
              " 'te',\n",
              " 'tem',\n",
              " 'tém',\n",
              " 'temos',\n",
              " 'tenha',\n",
              " 'tenham',\n",
              " 'tenhamos',\n",
              " 'tenho',\n",
              " 'terá',\n",
              " 'terão',\n",
              " 'terei',\n",
              " 'teremos',\n",
              " 'teria',\n",
              " 'teriam',\n",
              " 'teríamos',\n",
              " 'teu',\n",
              " 'teus',\n",
              " 'teve',\n",
              " 'tinha',\n",
              " 'tinham',\n",
              " 'tínhamos',\n",
              " 'tive',\n",
              " 'tivemos',\n",
              " 'tiver',\n",
              " 'tivera',\n",
              " 'tiveram',\n",
              " 'tivéramos',\n",
              " 'tiverem',\n",
              " 'tivermos',\n",
              " 'tivesse',\n",
              " 'tivessem',\n",
              " 'tivéssemos',\n",
              " 'tu',\n",
              " 'tua',\n",
              " 'tuas',\n",
              " 'um',\n",
              " 'uma',\n",
              " 'você',\n",
              " 'vocês',\n",
              " 'vos']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def removeStopWords(texto):\n",
        "  frases = []\n",
        "  for (palavras, emocao) in texto:\n",
        "    semStop = [p for p in palavras.split() if p not in stopwords]\n",
        "    frases.append((semStop, emocao))\n",
        "  return frases"
      ],
      "metadata": {
        "id": "eJUCHN_z62UL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(removeStopWords(dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilA-rVjT7wfh",
        "outputId": "e9a697a6-d2ef-481b-fe35-5341e1cd60be"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['estao', 'deixando', 'gente', 'sonhar'], 'alegria'), (['recebi', 'salario', 'extra'], 'alegria'), (['passaremos', 'Natal', 'familia'], 'alegria'), (['conseguirei', 'tirar', 'ferias', 'junto', 'voce'], 'alegria'), (['tirei', 'nota', 'dez', 'prova'], 'alegria'), (['consegui', 'emprego', 'novo'], 'alegria'), (['preco', 'carne', 'diminuiu'], 'alegria'), (['consegui', 'entregar', 'trabalho', 'dentro', 'prazo'], 'alegria'), (['filho', 'nasceu', 'saude'], 'alegria'), (['virada', 'ano', 'maravilhosa'], 'alegria'), (['perdi', 'celular'], 'tristeza'), (['vida', 'tristeza'], 'tristeza'), (['nao', 'aguento'], 'tristeza'), (['fazem', 'dois', 'anos'], 'tristeza'), (['infelizmente', 'despedido'], 'tristeza'), (['aumento', 'salario', 'nao', 'saiu'], 'tristeza'), (['perdi', 'aposta'], 'tristeza'), (['pneu', 'carro', 'furou', 'meio', 'caminho'], 'tristeza'), (['mudar', 'cidade', 'natal'], 'tristeza'), (['marido', 'abandonou'], 'tristeza')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extração dos Radicais das Palavras (stemming)**"
      ],
      "metadata": {
        "id": "XqMxZGfXFHhN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aplicaStemmer(texto):\n",
        "  stemmer = nltk.stem.RSLPStemmer()\n",
        "  frasesStemming = []\n",
        "  for(palavras, emocao) in texto:\n",
        "    comStemming = [str(stemmer.stem(p)) for p in palavras.split() if p not in stopwords]\n",
        "    frasesStemming.append((comStemming, emocao))\n",
        "  return frasesStemming"
      ],
      "metadata": {
        "id": "9co-zVTf_dYi"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frasesComStemming = aplicaStemmer(dataset)\n",
        "print(frasesComStemming)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bG7zoe8ZAWwp",
        "outputId": "fd02ae12-da7b-4238-da7f-49526d9c2fde"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(['esta', 'deix', 'gent', 'sonh'], 'alegria'), (['receb', 'salari', 'extr'], 'alegria'), (['pass', 'natal', 'famil'], 'alegria'), (['consegu', 'tir', 'fer', 'junt', 'voc'], 'alegria'), (['tir', 'not', 'dez', 'prov'], 'alegria'), (['consegu', 'empreg', 'nov'], 'alegria'), (['prec', 'carn', 'diminu'], 'alegria'), (['consegu', 'entreg', 'trabalh', 'dentr', 'praz'], 'alegria'), (['filh', 'nasc', 'saud'], 'alegria'), (['vir', 'ano', 'maravilh'], 'alegria'), (['perd', 'celul'], 'tristeza'), (['vid', 'trist'], 'tristeza'), (['nao', 'aguent'], 'tristeza'), (['faz', 'doi', 'ano'], 'tristeza'), (['infeliz', 'desped'], 'tristeza'), (['aument', 'salari', 'nao', 'saiu'], 'tristeza'), (['perd', 'apost'], 'tristeza'), (['pneu', 'carr', 'fur', 'mei', 'caminh'], 'tristeza'), (['mud', 'cidad', 'natal'], 'tristeza'), (['marid', 'abandon'], 'tristeza')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lista de palavras**"
      ],
      "metadata": {
        "id": "khaxtQqwGKb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscaPalavras(frases):\n",
        "  todasPalavras = []\n",
        "  for(palavras, emocao) in frases:\n",
        "    todasPalavras.extend(palavras)\n",
        "  return todasPalavras"
      ],
      "metadata": {
        "id": "eCG9blssBbav"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavras = buscaPalavras(frasesComStemming)\n",
        "print(palavras)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmvedbkOB4w3",
        "outputId": "fa345a9d-02bd-4e80-a3d8-58d2c936729f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['esta', 'deix', 'gent', 'sonh', 'receb', 'salari', 'extr', 'pass', 'natal', 'famil', 'consegu', 'tir', 'fer', 'junt', 'voc', 'tir', 'not', 'dez', 'prov', 'consegu', 'empreg', 'nov', 'prec', 'carn', 'diminu', 'consegu', 'entreg', 'trabalh', 'dentr', 'praz', 'filh', 'nasc', 'saud', 'vir', 'ano', 'maravilh', 'perd', 'celul', 'vid', 'trist', 'nao', 'aguent', 'faz', 'doi', 'ano', 'infeliz', 'desped', 'aument', 'salari', 'nao', 'saiu', 'perd', 'apost', 'pneu', 'carr', 'fur', 'mei', 'caminh', 'mud', 'cidad', 'natal', 'marid', 'abandon']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Frequência de palavras**"
      ],
      "metadata": {
        "id": "oiP1vneTGTgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def frequenciaPalavras(palavras):\n",
        "  palavras = nltk.FreqDist(palavras)\n",
        "  return palavras"
      ],
      "metadata": {
        "id": "FpKalvu8ErZR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frequencia = frequenciaPalavras(palavras)\n",
        "print(frequencia.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFlgM3idE1Vt",
        "outputId": "d7a48b89-4475-4bcd-e298-9ad8c61a9091"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('consegu', 3), ('salari', 2), ('natal', 2), ('tir', 2), ('ano', 2), ('perd', 2), ('nao', 2), ('esta', 1), ('deix', 1), ('gent', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Palavras únicas (sem repetição)**"
      ],
      "metadata": {
        "id": "ymQ6TGruGs4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def buscaPalavrasUnicas(frequencia):\n",
        "  unicas = frequencia.keys()\n",
        "  return unicas"
      ],
      "metadata": {
        "id": "BO-T0GjIGwFT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "palavrasUnicas = buscaPalavrasUnicas(frequencia)\n",
        "print(palavrasUnicas)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7eL0MJjgG9cd",
        "outputId": "202a7bb1-5707-44c9-a6ec-8b602d800bb5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['esta', 'deix', 'gent', 'sonh', 'receb', 'salari', 'extr', 'pass', 'natal', 'famil', 'consegu', 'tir', 'fer', 'junt', 'voc', 'not', 'dez', 'prov', 'empreg', 'nov', 'prec', 'carn', 'diminu', 'entreg', 'trabalh', 'dentr', 'praz', 'filh', 'nasc', 'saud', 'vir', 'ano', 'maravilh', 'perd', 'celul', 'vid', 'trist', 'nao', 'aguent', 'faz', 'doi', 'infeliz', 'desped', 'aument', 'saiu', 'apost', 'pneu', 'carr', 'fur', 'mei', 'caminh', 'mud', 'cidad', 'marid', 'abandon'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extração de palavras do texto**"
      ],
      "metadata": {
        "id": "99krVmX-Jfqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extraiPalavras(texto):\n",
        "  tex = set(texto)\n",
        "  caracteristicas = {}\n",
        "  for palavras in palavrasUnicas:\n",
        "    caracteristicas['%s' % palavras] = (palavras in tex)\n",
        "  return caracteristicas"
      ],
      "metadata": {
        "id": "x5DZ5BtwJk_y"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caracteristicasFrase = extraiPalavras(['esta', 'gent', 'dia'])\n",
        "print(caracteristicasFrase)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "un9q03AjKD4g",
        "outputId": "8c5cd344-33d7-48da-8a60-199635d9697c"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'esta': True, 'deix': False, 'gent': True, 'sonh': False, 'receb': False, 'salari': False, 'extr': False, 'pass': False, 'natal': False, 'famil': False, 'consegu': False, 'tir': False, 'fer': False, 'junt': False, 'voc': False, 'not': False, 'dez': False, 'prov': False, 'empreg': False, 'nov': False, 'prec': False, 'carn': False, 'diminu': False, 'entreg': False, 'trabalh': False, 'dentr': False, 'praz': False, 'filh': False, 'nasc': False, 'saud': False, 'vir': False, 'ano': False, 'maravilh': False, 'perd': False, 'celul': False, 'vid': False, 'trist': False, 'nao': False, 'aguent': False, 'faz': False, 'doi': False, 'infeliz': False, 'desped': False, 'aument': False, 'saiu': False, 'apost': False, 'pneu': False, 'carr': False, 'fur': False, 'mei': False, 'caminh': False, 'mud': False, 'cidad': False, 'marid': False, 'abandon': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetProcessado = nltk.classify.apply_features(extraiPalavras, frasesComStemming)\n",
        "print(datasetProcessado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJCyBKWYKbWW",
        "outputId": "7ae41fed-bc22-4680-f3de-84c3fd62b5f2"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[({'esta': True, 'deix': True, 'gent': True, 'sonh': True, 'receb': False, 'salari': False, 'extr': False, 'pass': False, 'natal': False, 'famil': False, 'consegu': False, 'tir': False, 'fer': False, 'junt': False, 'voc': False, 'not': False, 'dez': False, 'prov': False, 'empreg': False, 'nov': False, 'prec': False, 'carn': False, 'diminu': False, 'entreg': False, 'trabalh': False, 'dentr': False, 'praz': False, 'filh': False, 'nasc': False, 'saud': False, 'vir': False, 'ano': False, 'maravilh': False, 'perd': False, 'celul': False, 'vid': False, 'trist': False, 'nao': False, 'aguent': False, 'faz': False, 'doi': False, 'infeliz': False, 'desped': False, 'aument': False, 'saiu': False, 'apost': False, 'pneu': False, 'carr': False, 'fur': False, 'mei': False, 'caminh': False, 'mud': False, 'cidad': False, 'marid': False, 'abandon': False}, 'alegria'), ({'esta': False, 'deix': False, 'gent': False, 'sonh': False, 'receb': True, 'salari': True, 'extr': True, 'pass': False, 'natal': False, 'famil': False, 'consegu': False, 'tir': False, 'fer': False, 'junt': False, 'voc': False, 'not': False, 'dez': False, 'prov': False, 'empreg': False, 'nov': False, 'prec': False, 'carn': False, 'diminu': False, 'entreg': False, 'trabalh': False, 'dentr': False, 'praz': False, 'filh': False, 'nasc': False, 'saud': False, 'vir': False, 'ano': False, 'maravilh': False, 'perd': False, 'celul': False, 'vid': False, 'trist': False, 'nao': False, 'aguent': False, 'faz': False, 'doi': False, 'infeliz': False, 'desped': False, 'aument': False, 'saiu': False, 'apost': False, 'pneu': False, 'carr': False, 'fur': False, 'mei': False, 'caminh': False, 'mud': False, 'cidad': False, 'marid': False, 'abandon': False}, 'alegria'), ...]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classificador Naive Bayes - Treinamento**"
      ],
      "metadata": {
        "id": "X7IKEFAALq-W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = nltk.NaiveBayesClassifier.train(datasetProcessado)"
      ],
      "metadata": {
        "id": "_dv3g6yJL16L"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classificador.labels())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyBELCacMS4S",
        "outputId": "c2faee86-1966-4163-8e6f-203df673542f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['alegria', 'tristeza']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classificador.show_most_informative_features(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdO9dIFoMbbu",
        "outputId": "00fa7492-abd7-493b-df32-7941f751aa85"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Informative Features\n",
            "                 consegu = False          triste : alegri =      1.4 : 1.0\n",
            "                     nao = False          alegri : triste =      1.2 : 1.0\n",
            "                    perd = False          alegri : triste =      1.2 : 1.0\n",
            "                     tir = False          triste : alegri =      1.2 : 1.0\n",
            "                 abandon = False          alegri : triste =      1.1 : 1.0\n",
            "                  aguent = False          alegri : triste =      1.1 : 1.0\n",
            "                   apost = False          alegri : triste =      1.1 : 1.0\n",
            "                  aument = False          alegri : triste =      1.1 : 1.0\n",
            "                  caminh = False          alegri : triste =      1.1 : 1.0\n",
            "                    carn = False          triste : alegri =      1.1 : 1.0\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Classificando emoções em textos**"
      ],
      "metadata": {
        "id": "bPUz0bJEOcIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frase = \"teste\"\n",
        "testeStemming = []\n",
        "stemmer = nltk.stem.RSLPStemmer()\n",
        "for(palavras) in frase.split():\n",
        "  comStem = [p for p in palavras.split()]\n",
        "  testeStemming.append(str(stemmer.stem(comStem[0])))\n",
        "print(testeStemming)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AWA8fFOOgPW",
        "outputId": "192bf763-a2cf-4563-ace8-931aaf9988ef"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "teste = extraiPalavras(testeStemming)\n",
        "#print(teste)"
      ],
      "metadata": {
        "id": "ewGkNkysPPFe"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classificador.classify(teste))\n",
        "distribuicao = classificador.prob_classify(teste)\n",
        "for classe in distribuicao.samples():\n",
        "  print('%s: %f' % (classe, distribuicao.prob(classe)))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ti1h5H2Pff4",
        "outputId": "2eb41985-4a25-4db6-f52f-d7220b35f521"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tristeza\n",
            "alegria: 0.283771\n",
            "tristeza: 0.716229\n"
          ]
        }
      ]
    }
  ]
}